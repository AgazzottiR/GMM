# Toward Characteristic-Preserving Image-based Virtual Try-On Network

Reimplemented code for eccv2018 paper 'Toward Characteristic-Preserving Image-based Virtual Try-On Network'. 
The results may have some differences with those of the original code.

## Data preprocessing

We convert the original data [VITON](https://github.com/xthan/VITON) into different directories for easily use. 
Run the matlab code ```convert_data.m ``` under the original data root ```VITON/data```, and get the new format.
We use the json format for pose info as generated by [OpenPose](https://github.com/CMU-Perceptual-Computing-Lab/openpose).
Move these directories into our own dataroot ```data```.

## Geometric Matching Module

### training
We just use L1 loss for criterion in this code. 
TV norm constraints for the offsets will make GMM more robust.

**Example**
```
python train.py --name gmm_train_new --stage GMM --workers 4 --save_count 5000 --shuffle
```


### eval

Choose the different source data for eval with the option ```--datamodel```.

**Example**
```
python test.py --name gmm_traintest_new --stage GMM --workers 4 --datamode test --checkpoint checkpoints/gmm_train_new/gmm_final.pth
```

## Try-On Module
### training
An example training command is
```
python train.py --name tom_train_new --stage TOM --workers 4 --save_count 5000 --shuffle 
```
You can see the results in tensorboard, as show below.

### eavl


## Citation
If this code or dataset helps your research, please cite our paper:

